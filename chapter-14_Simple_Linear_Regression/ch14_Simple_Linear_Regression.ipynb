{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2768e7",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c13164",
   "metadata": {},
   "source": [
    "For linear relationship, we start with linear model   \n",
    "\n",
    "for this remember line equation:\n",
    "`y = mx + c`, Here m = slope and c = intercept\n",
    "\n",
    "Hypothesize that there are constants `ɑ(alpha)` and `β(beta)` <br>\n",
    "\n",
    "`y_i = β * x_i + ɑ + ɛ_i`\n",
    "\n",
    "- y_i = number of minutes user (i) spends on the site daily <br>\n",
    "- x_i = number of friends of user (i) <br>\n",
    "- β(beta) = slope = How many extra minutes a user spends for each additional friend.<br>\n",
    "- ɑ(alpha) = intecept = How much time a user would spend even with zero friends.<br>\n",
    "- ɛ = error term representing the fact that there are other factors not accounted for by this simple model <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a410e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming, we have determined such an alpha and beta, then we can make predictions simply with:\n",
    "\n",
    "def predict(alpha:float, beta:float,x_i)->float:\n",
    "    return beta*x_i + alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46523bd",
   "metadata": {},
   "source": [
    "#### How Do We Pick Alpha and Beta?\n",
    "\n",
    "We choose the values that make our predictions closest to the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91abc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(alpha:float, beta:float,x_i:float,y_i:float)-> float:\n",
    "    return predict(alpha,beta,x_i)-y_i         # error =  Predicted_Value - Actual_Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d7886",
   "metadata": {},
   "source": [
    "We need to know the total error of the entire dataset. But we can't just add the errors. If the prediction for x_1 is too high and the prediction for x_2 is too low, the errors may just cancel out.\n",
    "\n",
    "So instead we add up the squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e819083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "Vector = List[float]\n",
    "def sum_of_sqerrors(alpha:float, beta:float, x:Vector, y:Vector)-> float:\n",
    "    return sum(error(alpha,beta,x_i,y_i)**2\n",
    "               for x_i,y_i in zip(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d106de",
   "metadata": {},
   "source": [
    "#### Below code is from Ch-5 (Statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ce8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Correlation \n",
    " ## Covariance( for covariance both variables should)\n",
    "def mean(xs: List[float])-> float:\n",
    "    return sum(xs)/len(xs)\n",
    "\n",
    "def de_mean(xs:List[float]) -> List[float]:\n",
    "    x_bar = mean(xs)\n",
    "    return[x-x_bar for x in xs]\n",
    "\n",
    "\n",
    "def sum_of_squares(xs:List[float])-> float:\n",
    "    return sum(x_i*x_i for x_i in xs)\n",
    "\n",
    "def variance(xs:List[float])->float:\n",
    "    assert len(xs) >= 2 , \"variance requires at least two elements\"\n",
    "\n",
    "    n = len(xs)\n",
    "    deviations = de_mean(xs)\n",
    "    return(sum_of_squares(deviations)/(n-1))\n",
    "\n",
    "def standard_deviation(xs:List[float])-> float:\n",
    "    ''' The standard deviation is the square root of the variance '''\n",
    "    return math.sqrt(variance(xs))\n",
    "\n",
    "def dot(xs:List[float],ys:List[float]):\n",
    "    return sum(x_i*y_i for x_i,y_i in zip(xs,ys))\n",
    "\n",
    "def covariance(xs:List[float],ys:List[float])-> float:\n",
    "    assert len(xs) == len(ys), \"xs and ys must have same number of elements\"\n",
    "    n = len(xs)\n",
    "    return dot(de_mean(xs), de_mean(ys)) / (n-1)\n",
    "\n",
    "\n",
    "# Correlation\n",
    "def correlation(xs:List[float], ys:List[float])->float:\n",
    "    ''' Measures how much xs and ys vary in tandem about their means '''\n",
    "    stdev_x = standard_deviation(xs)\n",
    "    stdev_y = standard_deviation(ys)\n",
    "    if stdev_x>0 and stdev_y>0:\n",
    "        return covariance(xs,ys) / stdev_x / stdev_y\n",
    "    else:\n",
    "        return 0                     # if no variation, correlation is zero "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f999a",
   "metadata": {},
   "source": [
    "Using Calculus, the error-minimizing (alpha) and (beta) are given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0a8dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "Vector = List[float]\n",
    "\n",
    "def least_squares_fit(x:Vector, y:Vector)-> Tuple[float,float]:\n",
    "    \"\"\"\n",
    "    Given two vectors x and y, \n",
    "    find the least-squares values of alpha and beta\n",
    "    \"\"\"\n",
    "    beta = correlation(x,y) * standard_deviation(y) / standard_deviation(x)\n",
    "    alpha = mean(y) - beta * mean(x)\n",
    "    return alpha,beta\n",
    "\n",
    "\n",
    "# Quick test\n",
    "x = [i for i in range(-100,110,10)]\n",
    "y = [3*i-5 for i in x]\n",
    "\n",
    "# Should find that y = 3x-5\n",
    "assert least_squares_fit(x,y) == (-5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6342f5c",
   "metadata": {},
   "source": [
    "R² tells you how well your line explains the data. <br>\n",
    "\n",
    "R² = 1.0 − (Unexplained Variation)​ / (Total Variation)  <br>\n",
    "\n",
    "- Unexplained Variation = It is basically the error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c07592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sum_of_squares(y:Vector) -> float:\n",
    "    \"\"\" The total sqaured variation of y_i's from their mean \"\"\"\n",
    "    return sum(v**2 for v in de_mean(y))\n",
    "\n",
    "def r_squared(alpha:float, beta:float, x:Vector, y:Vector)-> float:\n",
    "    \"\"\" The fraction of variation in y captured by the model, which equals\n",
    "    1 - the fraction of variation in y not captured by the model \"\"\"\n",
    "\n",
    "    return 1.0 - (sum_of_sqerrors(alpha,beta,x,y) / total_sum_of_squares(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2134af42",
   "metadata": {},
   "source": [
    "#### Using Gradient Descent to find alpha and beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a021677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 306.684: 100%|██████████| 10000/10000 [00:05<00:00, 1720.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 15.45392345798616 and beta = 1.0161036071293024\n"
     ]
    }
   ],
   "source": [
    "import random, tqdm\n",
    "\n",
    "num_friends_good = list(range(0, 100, 5))\n",
    "daily_minutes_good = [0.9*x + 23 for x in num_friends_good]\n",
    "\n",
    "\n",
    "def scalar_multiplication(c:float, v:Vector)-> Vector:\n",
    "    return[c*x for x in v]\n",
    "\n",
    "def add(v:Vector, w:Vector)-> Vector:\n",
    "    return[v_i+w_i for v_i,w_i in zip(v,w)]\n",
    "\n",
    "def gradient_step(v:Vector, gradient:Vector, step_size: float) -> Vector:\n",
    "    \"\"\" Moves 'step size' in the `gradient` direction from `v` \"\"\"\n",
    "    assert len(v) == len(gradient)\n",
    "    step = scalar_multiplication(step_size, gradient)\n",
    "    return add(v,step)\n",
    " \n",
    "num_epochs = 10000\n",
    "random.seed(0) \n",
    " \n",
    "guess = [random.random(), random.random()]  # choose random value to start \n",
    " \n",
    "learning_rate = 0.00001 \n",
    " \n",
    "with tqdm.trange(num_epochs) as t: \n",
    "    for _ in t: \n",
    "        alpha, beta = guess \n",
    " \n",
    "        # Partial derivative of loss with respect to alpha \n",
    "        grad_a = sum(2 * error(alpha, beta, x_i, y_i) \n",
    "                     for x_i, y_i in zip(num_friends_good, \n",
    "                                         daily_minutes_good)) \n",
    " \n",
    "        # Partial derivative of loss with respect to beta \n",
    "        grad_b = sum(2 * error(alpha, beta, x_i, y_i) * x_i \n",
    "                     for x_i, y_i in zip(num_friends_good, \n",
    "                                         daily_minutes_good)) \n",
    " \n",
    "        # Compute loss to stick in the tqdm description \n",
    "        loss = sum_of_sqerrors(alpha, beta, \n",
    "                               num_friends_good, daily_minutes_good) \n",
    "        t.set_description(f\"loss: {loss:.3f}\") \n",
    " \n",
    "        # Finally, update the guess \n",
    "        guess = gradient_step(guess, [grad_a, grad_b], -learning_rate) \n",
    " \n",
    "# We should get pretty much the same results:\n",
    "alpha, beta = guess\n",
    "print(f\"alpha = {alpha} and beta = {beta}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4333956",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d540b6b",
   "metadata": {},
   "source": [
    "Maximum Likelihood Estimation is a method used to estimate model parameters by choosing values that make the observed data most probable.\n",
    "\n",
    "In short:\n",
    "Pick parameters that best explain the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d8f75c",
   "metadata": {},
   "source": [
    "## Steps in Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "### 1. Choose a Model\n",
    "Select a mathematical model that describes the relationship between variables.\n",
    "\n",
    "Example:\n",
    "y = α + βx + ε\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Assume a Distribution for Errors\n",
    "Assume how the random errors behave.  \n",
    "Most commonly, errors are assumed to follow a normal distribution:\n",
    "\n",
    "ε ~ Normal(0, σ)\n",
    "\n",
    "- Mean = 0 → no bias  \n",
    "- σ → typical size of errors  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Build the Likelihood Function\n",
    "Construct a function that measures how probable the observed data is given the parameters.\n",
    "\n",
    "L(θ) = P(data | θ)\n",
    "\n",
    "For independent observations, the total likelihood is the product of individual probabilities.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Maximize the Likelihood\n",
    "Find the parameter values that make the observed data most probable.\n",
    "\n",
    "When errors are normally distributed, maximizing likelihood is equivalent to minimizing the sum of squared errors (SSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
