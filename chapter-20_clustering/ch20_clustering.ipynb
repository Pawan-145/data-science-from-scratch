{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2bb1582",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Clustering is an example of unsupervised learning in which we work with completely unlabeled data (or in which our data has labels but we ignore them)\n",
    "\n",
    "- The clusters won't label themselves. You'll have to do that by looking at the data underlying each one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfee771",
   "metadata": {},
   "source": [
    "One of the simplest clustering methods is `k-means`\n",
    "\n",
    "In which the number of clusters **k** is choosen in advance\n",
    "\n",
    "`k = number of clusters we want`\n",
    "\n",
    "Then the goal is:\n",
    "- Divide the data into k groups so that points in each group are close to that groupâ€™s average (called the mean).\n",
    "\n",
    "We try to minimize:\n",
    "\n",
    "- The total squared distance between each point and the mean of its cluster\n",
    "\n",
    "\n",
    "There are a lot of ways to assign **n** points to **k** clusters, which means that finding an optimal clustering is a very hard problem.\n",
    "We will settle for an iterative algorithm that usually finds a good clustering:\n",
    "\n",
    "- 1. Start with a set of **k-means**, which are points in d-dimensional space\n",
    "- 2. Assign each point to the mean to which it is closed\n",
    "- 3. If no point's assignment has changed, stop and keep the clusters\n",
    "- 4. If some point's assignment has changed, recompute the means and returns to step 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d5c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measures how many coordinates two vectors differ in.\n",
    "\n",
    "from typing import List\n",
    "\n",
    "Vector = List[float]\n",
    "\n",
    "def num_differences(v1:Vector, v2:Vector) -> int:\n",
    "    assert len(v1) == len(v2)\n",
    "    return len([x1 for x1,x2 in zip(v1,v2) if x1 != x2])\n",
    "\n",
    "assert num_differences([1,2,3],[2,1,3])\n",
    "assert num_differences([1,2],[1,2]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c8ed0",
   "metadata": {},
   "source": [
    "We also need a function that, given some vectors and their assignment to clusters, computes the means of the clusters. It may be the case that some cluster has no points to assigned to it. We can't take the mean of an empty collection, so in this case we'll just randomly pick one of the points to serve as the \"mean\" of that cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29957abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import random\n",
    "\n",
    "def vector_sum(vectors: List[Vector]) -> Vector:\n",
    "    # check that vectors is not empty\n",
    "    assert vectors, \"no vectors provided!\"\n",
    "\n",
    "    # check the vectors are all the same size\n",
    "    num_elements = len(vectors[0])\n",
    "    assert all(len(v) == num_elements for v in vectors), \"different sizes\"\n",
    "    return [sum(vector[i] for vector in vectors) for i in range(num_elements)]\n",
    "\n",
    "def vector_mean(vectors: List[Vector])-> Vector:\n",
    "    num_elements = len(vectors)\n",
    "    return [(1/num_elements)*i for i in vector_sum(vectors)]\n",
    "\n",
    "def cluster_means(k: int, inputs: List[Vector], assignments: List[int]) -> List[Vector]:\n",
    "    clusters = [[] for i in range(k)]\n",
    "\n",
    "    for input, assignment in zip(inputs, assignments):\n",
    "        clusters[assignment].append(input)\n",
    "\n",
    "    # If a cluster is empty, we just use a random point\n",
    "    return [vector_mean(cluster) if cluster else random.choice(inputs) for cluster in clusters]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb1acc",
   "metadata": {},
   "source": [
    "We will use **tqdm** to track our progress but here we don't know how many iterations it will take. So we then use **itertools.count**, which creates an infinite iterable adn we will return out it when we are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4d4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "def dot(v:Vector,w:Vector)->Vector:\n",
    "    assert len(v) == len(w), \"vectors must be of same length\"\n",
    "    return sum(v_i*w_i for v_i,w_i in zip(v,w))\n",
    "\n",
    "def sum_of_squares(v:Vector)->float:\n",
    "    return dot(v,v)\n",
    "\n",
    "def subtract(v:Vector,w:Vector):\n",
    "    assert len(v) == len(w)\n",
    "    return[v_i-w_i for v_i, w_i in zip(v,w)]\n",
    "\n",
    "def squared_distance(v:Vector, w:Vector) -> float:\n",
    "    return sum_of_squares(subtract(v,w))\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, k:int) -> None:\n",
    "        self.k = k             # number of clusters\n",
    "        self.means = None\n",
    "\n",
    "    def classify(self, input: Vector) -> int:\n",
    "        \"\"\" Return the index of the cluster closet to the input \"\"\"\n",
    "        return min(range(self.k), key=lambda i: squared_distance(input, self.means[i]))\n",
    "    \n",
    "    def train(self, inputs: List[Vector]) -> None:\n",
    "        # Start with random assignments \n",
    "        assignments  = [random.randrange(self.k) for _ in inputs]\n",
    "\n",
    "        with tqdm.tqdm(itertools.count()) as t:\n",
    "            for _ in t:\n",
    "                # Compute means and find new assignments\n",
    "                self.means = cluster_means(self.k, inputs, assignments)\n",
    "                new_assignments = [self.classify(input) for input in inputs]\n",
    "\n",
    "                # check how many assignments changed and if we are done\n",
    "                num_changed = num_differences(assignments, new_assignments)\n",
    "                if num_changed == 0:\n",
    "                 return\n",
    "                \n",
    "                # Otherwise keep the new assignments and compute the new means\n",
    "                assignments = new_assignments\n",
    "                self.means = cluster_means(self.k, inputs, assignments)\n",
    "                t.set_description(f\"changed: {num_changed} / {len(inputs)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef74cc61",
   "metadata": {},
   "source": [
    "## Choosing (k)\n",
    "\n",
    "There are various ways to choose **k**. One that is resonably easy to understand involves plotting the **sum of squared errors**(between each point and the mean of its cluster) as function of **k** and looking at where the graph \"bends\". Also known as `Elbow Method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7243221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def squared_clustering_errors(inputs: List[Vector], k:int) -> float:\n",
    "    \"\"\" Finds the total squared error from k-means clustering the inputs \"\"\"\n",
    "    clusterer = KMeans(k)\n",
    "    clusterer.train(inputs)\n",
    "    means = clusterer.means\n",
    "    assignments = [clusterer.classify(input) for input in inputs]\n",
    "\n",
    "    return sum(squared_distance(input,means[cluster]) for input, cluster in zip(inputs, assignments))\n",
    "\n",
    "# now plot from 1 up to len(inputs) clusters\n",
    "\n",
    "ks = range(1,len(inputs)+1)\n",
    "errors = [squared_clustering_errors(inputs,k) for k in ks]\n",
    "\n",
    "plt.plot(ks,errors)\n",
    "plt.xticks(ks)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"total squared error\")\n",
    "plt.title(\"Total Error vs. # of Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e4a87",
   "metadata": {},
   "source": [
    "## Example: Clustering Colors\n",
    "\n",
    "Computer images can be represented as two-dimensional arrays of pixels, where each pixel is itself a three-dimensional vector(red, green, blue) indicating its color\n",
    "\n",
    "Image as a 2D Array\n",
    "\n",
    "If an image is:\n",
    "\n",
    "- Height = 3 pixels\n",
    "- Width = 4 pixels\n",
    "\n",
    "It looke like:\n",
    "\n",
    "[\n",
    "  [[R,G,B], [R,G,B], [R,G,B], [R,G,B]],\n",
    "\n",
    "  [[R,G,B], [R,G,B], [R,G,B], [R,G,B]],\n",
    "\n",
    "  [[R,G,B], [R,G,B], [R,G,B], [R,G,B]]\n",
    "]\n",
    "\n",
    "\n",
    "Creating a five-color version of the image , then entails:\n",
    "\n",
    " 1. Choosing five colors.\n",
    " 2. Assigning one of those colors to each pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60914a4",
   "metadata": {},
   "source": [
    "To start with, we need a way to load image into Python. We can do this  with matplotlib, if  we first install the pillow library:\n",
    "\n",
    "`pip install pillow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8207769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\coding_cadet\\desktop\\data_science\\venv\\lib\\site-packages (12.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a892f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"girl_with_book.jpg\"\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread(image_path)/256                  # Rescale to between 0 and 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36626f",
   "metadata": {},
   "source": [
    "Behind the scenes **img** is a **NumPy** array, but for our purposes, we can treat it as a list of lists\n",
    "\n",
    "`img[i][j]` is the pixel in the ith rowa nd jth column, each pixel is the list of `[red, green, blue]` of numbers between 0 and 1 indicating the color of that pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_row = img[0]\n",
    "top_left_pixel = top_row[0]\n",
    "red, green, blue = top_left_pixel\n",
    "\n",
    "# We can get flattened list of all the pixels\n",
    "# .tolist() converts a Numpy array to a python list\n",
    "\n",
    "pixels = [pixel.tolist() for row in img for pixel in row]\n",
    "\n",
    "# Now feed them to our clusters\n",
    "\n",
    "clusterer  = KMeans(5)\n",
    "clusterer.train(pixels)   # this might take a while\n",
    "\n",
    "# Once it finishes, We just construct a new image with the same format\n",
    "def recolor(pixel: Vector) -> Vector:\n",
    "    cluster = clusterer.classify(pixel)         # index of the closest cluster\n",
    "    return clusterer.means[cluster]             # mean of the closes cluster\n",
    "\n",
    "new_img = [[recolor(pixel) for pixel in row] for row in img]\n",
    "\n",
    "# display it, using plt.imshow\n",
    "plt.imshow(new_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219132a",
   "metadata": {},
   "source": [
    "## Bottom-Up Hierarchical Clustering\n",
    "\n",
    "An alternative approach to clustering is to \"grow\" clusters from the bottom up.\n",
    "\n",
    "We can do this in the following way:\n",
    "\n",
    " 1. Make each input its own cluster of one.\n",
    " 2. As long as there are multiple clusters remaining, find the two closest clusters and merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f503332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our values will live in leaf clusters\n",
    "\n",
    "from typing import NamedTuple, Union,List\n",
    "Vector = List[float]\n",
    "\n",
    "class Leaf(NamedTuple):\n",
    "    value: Vector\n",
    "\n",
    "leaf1 = Leaf([10, 20])\n",
    "leaf2 = Leaf([30, -15])\n",
    "\n",
    "\n",
    "class Merged(NamedTuple):\n",
    "    children: tuple\n",
    "    order: int\n",
    "\n",
    "merged = Merged((leaf1,leaf2), order=1)\n",
    "\n",
    "Cluster = Union[Leaf, Merged]\n",
    "\n",
    "#A cluster can be either:\n",
    "#A Leaf (single point)\n",
    "# OR a Merged cluster (group of clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e03241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that recursively return all the values contained in a (possible merged) cluster\n",
    "\n",
    "def get_values(cluster: Cluster) -> List[Vector]:\n",
    "    if isinstance(cluster, Leaf):\n",
    "        return [cluster.value]\n",
    "    \n",
    "    else:\n",
    "        return [value \n",
    "                for child in cluster.children\n",
    "                for value in get_values(child)]\n",
    "    \n",
    "assert get_values(merged) == [[10, 20], [30, -15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e004706",
   "metadata": {},
   "source": [
    "In order to merge the closest clusters, we need some notion of the distance between clusters.\n",
    "\n",
    "1. Minimum distance (Single Linkage)\n",
    "2. Maximun distance (Complete Linkage)\n",
    "3. Average distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe34c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import math\n",
    "\n",
    "\n",
    "def distance(v:Vector, w:Vector) -> float:\n",
    "    return math.sqrt(squared_distance(v,w)) \n",
    "\n",
    "def cluster_distance(cluster1: Cluster, \n",
    "                     cluster2: Cluster, \n",
    "                     distance_agg: Callable = min) -> float: \n",
    "    \"\"\"\n",
    "    compute all the pairwise distances between cluster1 and cluster2\n",
    "    and apply the aggregation function _distance_agg_ to the resulting list\n",
    "    \"\"\" \n",
    "    return distance_agg([distance(v1, v2) \n",
    "                         for v1 in get_values(cluster1) \n",
    "                         for v2 in get_values(cluster2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678776f",
   "metadata": {},
   "source": [
    "We will use merge order slot to track the order.\n",
    "\n",
    "Since **Leaf** clusters were never merged, we will assign them infinity the highest possible value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc97a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_order(cluster: Cluster) -> float:\n",
    "    if isinstance(cluster, Leaf):\n",
    "        return float('inf')      # was never merged\n",
    "    else:\n",
    "        return cluster.order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b268159",
   "metadata": {},
   "source": [
    "Since **Leaf** clusters don't have children, we will create and add a helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5b6945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def get_children(cluster: Cluster):\n",
    "    if isinstance(cluster,Leaf):\n",
    "        raise TypeError(\"Leaf has no children\")\n",
    "    else:\n",
    "        return cluster.children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a48696",
   "metadata": {},
   "source": [
    "Creating the clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_up_cluster(inputs: List[Vector], distance_agg: Callable = min) -> Cluster:\n",
    "    \n",
    "    # Start with all leaves\n",
    "    clusters: List[Cluster] = [Leaf(input) for input in inputs]\n",
    "\n",
    "    def pair_distance(pair: Tuple[Cluster, Cluster]) -> float:\n",
    "        return cluster_distance(pair[0],pair[1],distance_agg)\n",
    "    \n",
    "    # as long as we have more than one cluster left...\n",
    "    while len(clusters) > 1:\n",
    "        # find two closest clusters\n",
    "        c1,c2 = min(((cluster1,cluster2) for i,cluster1 in enumerate(clusters)\n",
    "                    for cluster2 in clusters[:i]), key=pair_distance)\n",
    "        \n",
    "        # remove them from the list of clusters\n",
    "        clusters = [c for c in clusters if c!= c1 and c != c2]\n",
    "\n",
    "        # merge them using merge_order = # of clusters left\n",
    "        merged_cluster = Merged((c1,c2), order = len(clusters))\n",
    "\n",
    "        # and add their merge\n",
    "        clusters.append(merged_cluster)\n",
    "        \n",
    "    # when there's only one cluster left return it\n",
    "    return clusters[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafcc6fc",
   "metadata": {},
   "source": [
    "Function that generates any numebr fo clusters by performing the appropriate number of unmerges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clusters(base_cluster: Cluster, \n",
    "                      num_clusters: int) -> List[Cluster]: \n",
    "    # start with a list with just the base cluster \n",
    "    clusters = [base_cluster] \n",
    " \n",
    "    # as long as we don't have enough clusters yet... \n",
    "    while len(clusters) < num_clusters: \n",
    "        # choose the last-merged of our clusters \n",
    "        next_cluster = min(clusters, key=get_merge_order) \n",
    "        # remove it from the list \n",
    "        clusters = [c for c in clusters if c != next_cluster] \n",
    " \n",
    "        # and add its children to the list (i.e., unmerge it) \n",
    "        clusters.extend(get_children(next_cluster)) \n",
    " \n",
    "    # once we have enough clusters... \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0cd267",
   "metadata": {},
   "source": [
    "For example, if we want to generate three clusters we can just do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cluster = bottom_up_cluster(inputs)\n",
    "\n",
    "three_clusters = [get_values(cluster) for cluster in generate_clusters(base_cluster,3 )]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
