{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9c39cf",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae52bf2",
   "metadata": {},
   "source": [
    "`P(S∣B)=[P(B∣S)P(S)]/[P(B∣¬S)P(¬S)+P(B∣S)P(S)]​`                            \n",
    "\n",
    "The numerator is probability that a message is span and contains bitcoin, while the denominator is just the probability that All emails that contain “Bitcoin”, whether spam or not.\n",
    "\n",
    "S = spam, B = Bitcoin and ¬S = Not Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde5352",
   "metadata": {},
   "source": [
    "Now imagine checking many words like:\n",
    "\n",
    " “bitcoin”, “rolex”, “free”, “offer”, “win”, etc.\n",
    "\n",
    "Each word becomes a clue.\n",
    "\n",
    "The question becomes:\n",
    "\n",
    " If an email contains several spam-like words, how likely is it spam?\n",
    "\n",
    " We define:\n",
    "\n",
    "Xi = event that the message contains word i\n",
    "\n",
    "Example:\n",
    "\n",
    "X₁ → contains “bitcoin”\n",
    "\n",
    "X₂ → contains “rolex”\n",
    "\n",
    "We estimate:\n",
    "\n",
    "P(Xi | S) → chance a spam email contains that word\n",
    "\n",
    "P(Xi | ¬S) → chance a normal email contains that word\n",
    "\n",
    "These are learned from past emails.\n",
    "\n",
    "The KEY Assumption (Why it’s called Naive)\n",
    "\n",
    "Naive Bayes assumes:\n",
    "\n",
    " Words behave independently.\n",
    "\n",
    "Meaning:\n",
    "\n",
    "If you already know the email has “bitcoin”, it tells you NOTHING about whether it also has “rolex”.\n",
    "\n",
    "Here Independence is instead of calculating joint probability, we simply multiply:\n",
    "\n",
    "`P(X1​,X2​,...,Xn​∣S)=P(X1​∣S)×P(X2​∣S)×...×P(Xn​∣S)`\n",
    "\n",
    "Probability spam contains ALL these words = multiply the individual probabilities.\n",
    "\n",
    "\n",
    "#### Underflow \n",
    "\n",
    "In this computers don't deal with floating-point numbers too close to 0.\n",
    "\n",
    "example:\n",
    "0.01 × 0.02 × 0.03 × 0.01 ...\n",
    "\n",
    "after too many multiplication it becomes:\n",
    "0.0000000000000003\n",
    "\n",
    "Computers struggle with numbers this tiny.\n",
    "\n",
    "###### To deal with this use :\n",
    "`log(a × b) = log(a) + log(b)`\n",
    "so instead multiplying `p1 × p2 × p3` \n",
    "We compute: `log(p1) + log(p2) + log(p3)`\n",
    "To convert back use exp as: `exp(log(p1)+....log(pn)) = p1+......+pn`\n",
    "\n",
    "## Smoothing\n",
    "If spam word that is 'data' occurs in non spam messages during training then p(data|S) = 0. The result is that our Naive Bayes Classifier would always assign spam probability 0 to any message containing the word 'data'.\n",
    "\n",
    "To avoid this we use SMOOTHING.\n",
    "To fix this, we pretend we saw every word at least a few times.<br>\n",
    "`P(Xi​∣S)= (k+number of spam containing word)/(2k+total spam)​` <br>\n",
    "Here, usually k = 1, k is pseudecount, estimates the probaility of seeing the word in spam message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "870ea16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation \n",
    "\"\"\"\n",
    "Tokenization in strings is the process of breaking a continuous text or string into smaller, meaningful units called \"tokens\" (such as words, numbers, or symbols) using defined delimiters like spaces, commas, or special characters.\n",
    "\"\"\"\n",
    "from typing import Set\n",
    "import re\n",
    "def tokenize(text:str) -> Set[str]:\n",
    "    text = text.lower()       #convert to lowercase\n",
    "    all_words = re.findall(\"[a-z0-9]+\",text)      #extract the words\n",
    "    return set(all_words)\n",
    "\n",
    "assert tokenize(\"Data Science is Science\") == {\"data\",\"science\",\"is\"}\n",
    "\n",
    "\n",
    "# Defining our training data\n",
    "from typing import NamedTuple\n",
    "\n",
    "class Message(NamedTuple):\n",
    "    text:str\n",
    "    is_spam:bool\n",
    "\n",
    "\n",
    "from typing import List, Tuple, Dict, Iterable\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self,k:float=0.5)->None:\n",
    "        self.k = k       # Smoothing Factor\n",
    "\n",
    "        self.tokens: Set[str] = set()\n",
    "        self.token_spam_counts:Dict[str,int] = defaultdict(int)\n",
    "        self.token_ham_counts: Dict[str,int] = defaultdict(int)\n",
    "        self.spam_messages = self.ham_messages = 0                 # ham_messages = non-spam_messages\n",
    "\n",
    "    def train(self,messages:Iterable[Message])->None:\n",
    "        for message in messages:\n",
    "            # Increment message counts\n",
    "            if message.is_spam:\n",
    "                self.spam_messages +=1\n",
    "            else:\n",
    "                self.ham_messages += 1\n",
    "\n",
    "            # Increment word counts\n",
    "            for token in tokenize(message.text):\n",
    "                self.tokens.add(token)\n",
    "                if message.is_spam:\n",
    "                    self.token_spam_counts[token] += 1\n",
    "                else:\n",
    "                    self.token_ham_counts[token] += 1\n",
    "                 \n",
    "#Now we have to predict P(spam|token). To apply Bayes's theorem we need to know P(token|spam) and P(token|ham) for each   token in vocabulary. We will create 'private' helper function to compute this \n",
    "\n",
    "    def _probabilities(self,token:str) -> Tuple[float,float]:\n",
    "        \"\"\" returns P(token/spam) and P(token/ham) \"\"\"\n",
    "        spam = self.token_spam_counts[token]\n",
    "        ham = self.token_ham_counts[token]\n",
    "\n",
    "        p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "        p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "        return p_token_spam, p_token_ham\n",
    "\n",
    "# Predict method\n",
    "    def predict(self,text:str)-> float:\n",
    "        text_tokens = tokenize(text)\n",
    "        log_prob_if_spam = log_prob_if_ham = 0.0\n",
    "        \n",
    "        # Iterate through each word in our vocabulary\n",
    "        for token in self.tokens:\n",
    "            prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "            # If *token* appears in the message,\n",
    "            # add the log probability of seeing it \n",
    "            if token in text_tokens:\n",
    "                log_prob_if_spam += math.log(prob_if_spam)\n",
    "                log_prob_if_ham += math.log(prob_if_ham)\n",
    "\n",
    "            # Otherwise add the log probability of _not_ seeing it,\n",
    "            # which is log(1-probability of seeing it)\n",
    "            else:\n",
    "                log_prob_if_spam += math.log(1-prob_if_spam)\n",
    "                log_prob_if_ham += math.log(1-prob_if_ham)\n",
    "\n",
    "        prob_if_spam = math.exp(log_prob_if_spam)\n",
    "        prob_if_ham = math.exp(log_prob_if_ham)\n",
    "        return prob_if_spam/(prob_if_spam+prob_if_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549e2ec",
   "metadata": {},
   "source": [
    "## Testing Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c141b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [Message(\"spam rules\", is_spam=True),\n",
    "           Message(\"ham rules\", is_spam=False),\n",
    "           Message(\"hello ham\", is_spam=False)]\n",
    "\n",
    "model = NaiveBayesClassifier(k=0.5)\n",
    "model.train(messages)\n",
    "\n",
    "assert model.tokens == {\"spam\",\"ham\",\"hello\", \"rules\"}\n",
    "assert model.spam_messages == 1\n",
    "assert model.ham_messages == 2\n",
    "assert model.token_spam_counts == {\"spam\":1,\"rules\":1}\n",
    "assert model.token_ham_counts == {\"ham\":2,\"rules\":1,\"hello\":1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c0291a",
   "metadata": {},
   "source": [
    "## Using Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb96b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coding_cadet\\AppData\\Local\\Temp\\ipykernel_29104\\4000477365.py:18: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tf.extractall(OUTPUT_DIR)\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO     # so we can treat bytes as file\n",
    "import requests\n",
    "import tarfile              # are in .tar.bz format\n",
    "\n",
    "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "FILES = [\"20021010_easy_ham.tar.bz2\", \n",
    "         \"20021010_hard_ham.tar.bz2\", \n",
    "         \"20021010_spam.tar.bz2\"] \n",
    "\n",
    "OUTPUT_DIR = 'spam_data'\n",
    "for filename in FILES:\n",
    "    content = requests.get(f\"{BASE_URL}/{filename}\").content\n",
    "    \n",
    "    # Wrap the in-memory bytes so we can use them as a \"file.\" \n",
    "    fin = BytesIO(content)\n",
    "\n",
    "    # And extract all the files to the specified output dir.\n",
    "    with tarfile.open(fileobj=fin,mode='r:bz2') as tf:\n",
    "        tf.extractall(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(True, False): 500, (False, False): 325})\n"
     ]
    }
   ],
   "source": [
    "\"\"\" We look through the files, they all seem to start with 'Subject'. \"\"\"\n",
    "\n",
    "# modify the path to whenever you've put the files\n",
    "import glob, re\n",
    "\n",
    "path = \"spam_data/*/*\"\n",
    "\n",
    "data:List[Message] = []\n",
    "\n",
    "# glob.glob returns every filename that matches the wildcarded path\n",
    "for filename in glob.glob(path):\n",
    "    is_spam = \"ham\" not in filename\n",
    "\n",
    "    # There are some garbage characters in the emails; the errors='ignore'\n",
    "    # skips them instead of raising an exception\n",
    "    with open(filename, errors='ignore') as email_file:\n",
    "        for line in email_file:\n",
    "            if line.startswith(\"Subject:\"):\n",
    "                subject = line.lstrip(\"Subject: \")\n",
    "                data.append(Message(subject, is_spam))\n",
    "                break \n",
    "\n",
    "\n",
    "# Now split the data\n",
    "import random\n",
    "from typing import TypeVar\n",
    "X = TypeVar('X')\n",
    "\n",
    "def split_data(data:List[X],prob:int)-> List[X]:\n",
    "    data = data[:]\n",
    "    cut = int(len(data)*prob)\n",
    "    return data[:cut], data[cut:]\n",
    "\n",
    "random.seed(0)\n",
    "train_messages, test_messages = split_data(data,0.75)\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "model.train(train_messages)\n",
    "\n",
    "# Let's generate some predictions and check the model\n",
    "from collections import Counter\n",
    "\n",
    "predictions = [(message,model.predict(message.text))\n",
    "               for message in test_messages] \n",
    "\n",
    "confusion_matrix = Counter((message.is_spam, spam_probability>0.5)\n",
    "                           for message,spam_probability in predictions)\n",
    "\n",
    "print(confusion_matrix)                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spammiest_words ['done', 'scissors', 'outdoors', 'mice', 'passing', 'strength', 'epidemic', 'stepfather', 'curling', 'est']\n",
      "hammiest_words ['re', 'the', 'for', 'of', 'to', 'in', 'a', 'satalk', 'spambayes', 's']\n"
     ]
    }
   ],
   "source": [
    "def p_spam_given_token(token:str, model:NaiveBayesClassifier)->float:\n",
    "    prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "\n",
    "    return prob_if_spam/(prob_if_spam+prob_if_ham)\n",
    "\n",
    "words = sorted(model.tokens,key=lambda t:p_spam_given_token(t,model)) \n",
    "print(\"Spammiest_words\",words[-10:])\n",
    "print('hammiest_words',words[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
