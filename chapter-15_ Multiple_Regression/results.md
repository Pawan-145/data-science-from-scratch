# Chapter 15 – Results

## Objective

Build a Multiple Regression model from scratch to predict outcomes using several independent variables.

---

## What Was Implemented

✔ Vector-based prediction using dot product  
✔ Gradient Descent optimization  
✔ Squared error minimization  
✔ R² evaluation  
✔ Bootstrap sampling  
✔ Hypothesis testing (t-statistic & p-values)  
✔ Ridge and Lasso regularization  

---

## Key Achievements

### ✅ Model Successfully Learned Coefficients
Gradient descent converged toward stable beta values.

---

### ✅ Reliable Predictions Generated
The regression captured relationships between multiple features and the target variable.

---

### ✅ Bootstrap Provided Insight into Stability
Standard errors helped measure how trustworthy each coefficient was.

---

### ✅ Statistical Testing Validated Features
t-tests and p-values identified which variables significantly influenced predictions.

---

### ✅ Regularization Reduced Overfitting Risk
Ridge shrank large coefficients while Lasso demonstrated feature selection capability.

---

## Observations

- Adding features improves explanatory power but increases overfitting risk.
- Regularization is essential when dealing with many variables.
- Gradient descent scales well compared to analytical methods.

---

## Skills Strengthened

- Multivariable modeling  
- Optimization techniques  
- Statistical inference  
- Feature engineering  
- Model evaluation  
- Bias-variance control  

---

## Final Verdict

✅ Successfully implemented Multiple Regression from scratch.  
✅ Applied statistical reasoning to evaluate coefficients.  
✅ Learned industry-critical techniques like regularization.  

