# ğŸŒ³ Chapter 17 â€” Decision Trees & Random Forests

## ğŸ“Œ Overview

This notebook implements **Decision Trees from scratch** using entropy and the **ID3 algorithm**, followed by a conceptual deep dive into **Random Forests** and ensemble learning.

The goal is to understand how machines make structured decisions by repeatedly splitting data into smaller subsets.

---

# ğŸ¯ Objectives

âœ” Understand entropy and information gain  
âœ” Learn how datasets are partitioned  
âœ” Build a decision tree classifier  
âœ” Handle unknown attribute values  
âœ” Explore overfitting  
âœ” Understand Random Forest and bagging  

---

#  Concepts Covered

## Decision Trees
- Tree-based supervised learning
- Recursive splitting
- Leaf vs Split nodes

## Entropy
Measures impurity in data.

## Partition Entropy
Helps select the best feature for splitting.

## ID3 Algorithm
Builds trees by minimizing entropy.

## Overfitting
Major weakness of single trees.

## Random Forest
An ensemble technique that combines multiple trees to improve performance.

---

# âš™ Implementation Highlights

The notebook includes:

-  Entropy computation  
-  Partitioning functions  
-  Recursive tree builder  
-  Classification logic  
-  Default handling for unseen values  

Assertions ensure correctness throughout.

---

# ğŸ— Project Structure

- `chapter-17_decision_trees.ipynb`
- `notes.md`
- `results.md`

  
---

#  Key Learnings

- Lower entropy â†’ better splits.
- Trees are interpretable but unstable.
- Random Forest dramatically improves reliability.

---

#  When to Use Decision Trees?

âœ” When interpretability matters  
âœ” When features are categorical  
âœ” When preprocessing should be minimal  

---

# âš  When to Prefer Random Forest?

âœ” When accuracy is critical  
âœ” When dataset is noisy  
âœ” When overfitting is likely  

---

#  Conclusion

This chapter demonstrates how powerful tree-based models are and why ensemble methods like Random Forest are widely used in production ML systems.

Understanding Decision Trees builds a strong foundation for advanced models such as:

- Gradient Boosting  
- XGBoost  
- LightGBM  

---



